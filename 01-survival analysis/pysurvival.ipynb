{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pysurvival.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debanjanm/statistics/blob/main/01-survival%20analysis/pysurvival.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFwrXmCwnSOM"
      },
      "source": [
        "pip install pysurvival"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tixVrKmIoFl4"
      },
      "source": [
        "####  Importing packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pysurvival.models.simulations import SimulationModel\n",
        "from pysurvival.models.semi_parametric import CoxPHModel\n",
        "from pysurvival.utils.metrics import concordance_index\n",
        "from pysurvival.utils.display import integrated_brier_score\n",
        "#%pylab inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAt5vqkZGjbI"
      },
      "source": [
        "**DATA PRE-PROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et2GHQEBoyxb"
      },
      "source": [
        "####  loading dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikR4NDn_paTT"
      },
      "source": [
        "import io\n",
        "data = io.BytesIO(uploaded['SURVIVAL.csv'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH2pvbDLpcDq"
      },
      "source": [
        "dataset = pd.read_csv(data) "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2rZLwl99dux"
      },
      "source": [
        "# Showing a few data-points \n",
        "dataset.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv__dmuJ-QnM"
      },
      "source": [
        "df1 = dataset.iloc[:,[2,3,5,6,7,8,9,10,11,12]].copy()\n",
        "df2 = dataset.iloc[:,[2,3,4,6,7,8,9,10,11,12]].copy()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Thnk0T-1FN"
      },
      "source": [
        "df1.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTPRxYJ5y_CS"
      },
      "source": [
        "# Data types\n",
        "df1.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV_Mpal5yRAu"
      },
      "source": [
        "# Creating one-hot vectors\n",
        "categories = ['Metagene', 'TUMOR_STAGE', 'MENOPAUSAL_STATE',\n",
        "              'TUMOR_SIZE', 'HISTOLOGICAL_SUBTYPE', 'BREAST_SURGERY']\n",
        "df11 = pd.get_dummies(df1, columns=categories, drop_first=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEbtZaAUCx7_"
      },
      "source": [
        "#### Creating the modeling dataset\n",
        "r1, c1 = df1.shape"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RFwwFRCd5r3"
      },
      "source": [
        "# Creating the time and event columns\n",
        "time_column = 'OS_MONTHS'\n",
        "event_column = 'OS_STATUS'\n",
        "\n",
        "# Extracting the features\n",
        "features = np.setdiff1d(df11.columns, [time_column, event_column] ).tolist()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjtrCUIoAp_t"
      },
      "source": [
        "# Building training and testing sets #\n",
        "index_train, index_test = train_test_split( range(r1), test_size = 0.2)\n",
        "data_train = df11.loc[index_train].reset_index( drop = True )\n",
        "data_test  = df11.loc[index_test].reset_index( drop = True )\n",
        "\n",
        "# Creating the X, T and E inputs\n",
        "X_train, X_test = data_train[features], data_test[features]\n",
        "T_train, T_test = data_train[time_column], data_test[time_column]\n",
        "E_train, E_test = data_train[event_column], data_test[event_column]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2pwqU9gHYuI"
      },
      "source": [
        "**Cox Proportional Hazard model**\n",
        "*Standard CoxPH*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sng_4cKXroJa"
      },
      "source": [
        "#### Creating an instance of the Cox PH model and fitting the data.\n",
        "# Building the model\n",
        "coxph = CoxPHModel()\n",
        "coxph.fit(X_train, T_train, E_train, lr=0.5, l2_reg=1e-2, init_method='zeros')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRGTNzF_0KBG"
      },
      "source": [
        "#### Cross Validation / Model Performances\n",
        "c_index = concordance_index(coxph, X_test, T_test, E_test) #0.55\n",
        "print('C-index: {:.2f}'.format(c_index))\n",
        "\n",
        "ibs = integrated_brier_score(coxph, X_test, T_test, E_test, t_max=10,\n",
        "            figure_size=(20, 6.5) )\n",
        "print('IBS: {:.2f}'.format(ibs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsVfE4ysH6Or"
      },
      "source": [
        "**Cox Proportional Hazard model**\n",
        "*DeepSurv/Nonlinear CoxPH*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD6xJpXC12DS"
      },
      "source": [
        "from pysurvival.models.semi_parametric import NonLinearCoxPHModel"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVY6Ti1W1eUx"
      },
      "source": [
        "#### Creating an instance of the NonLinear CoxPH model and fitting the data.\n",
        "\n",
        "# Defining the MLP structure. Here we will build a 1-hidden layer \n",
        "# with 150 units and `BentIdentity` as its activation function\n",
        "structure = [ {'activation': 'BentIdentity', 'num_units': 150},  ]\n",
        "\n",
        "# Building the model\n",
        "nonlinear_coxph = NonLinearCoxPHModel(structure=structure)\n",
        "nonlinear_coxph.fit(X_train, T_train, E_train, lr=1e-3, init_method='xav_uniform')\n",
        "\n",
        "\n",
        "#### 5 - Cross Validation / Model Performances\n",
        "c_index = concordance_index(nonlinear_coxph, X_test, T_test, E_test) #0.56\n",
        "print('C-index: {:.2f}'.format(c_index))\n",
        "\n",
        "ibs = integrated_brier_score(nonlinear_coxph, X_test, T_test, E_test, t_max=10,\n",
        "            figure_size=(20, 6.5) )\n",
        "print('IBS: {:.2f}'.format(ibs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DaL0u3lIOWC"
      },
      "source": [
        "**Multi-Task Logistic Regression (MTLR)**\n",
        "*Linear MTLR model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC_Aozer2K2p"
      },
      "source": [
        "from pysurvival.models.multi_task import LinearMultiTaskModel"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XM9lDL72LWR"
      },
      "source": [
        "#### Creating an instance of the Linear MTLR model and fitting the data.\n",
        "# Building the model\n",
        "l_mtlr = LinearMultiTaskModel(bins=50)\n",
        "l_mtlr.fit(X_train, T_train, E_train, lr=1e-3, init_method='orthogonal')\n",
        "\n",
        "\n",
        "#### 5 - Cross Validation / Model Performances\n",
        "c_index = concordance_index(l_mtlr, X_test, T_test, E_test) #0.52\n",
        "print('C-index: {:.2f}'.format(c_index))\n",
        "\n",
        "ibs = integrated_brier_score(l_mtlr, X_test, T_test, E_test, t_max=30,\n",
        "            figure_size=(20, 6.5) )\n",
        "print('IBS: {:.2f}'.format(ibs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyreai3oIciF"
      },
      "source": [
        "**Multi-Task Logistic Regression (MTLR)**\n",
        "*Neural MTLR model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbdLFTMP2dp4"
      },
      "source": [
        "from pysurvival.models.multi_task import NeuralMultiTaskModel"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKd5Sdo32fLa"
      },
      "source": [
        "#### Creating an instance of the Neural MTLR model and fitting the data.\n",
        "\n",
        "# Defining the MLP structure. Here we will build a 1-hidden layer \n",
        "# with 150 units and `Swish` as its activation function\n",
        "structure = [ {'activation': 'ReLU', 'num_units': 150},  ]\n",
        "\n",
        "# Building the model\n",
        "n_mtlr = NeuralMultiTaskModel(structure=structure, bins=150)\n",
        "n_mtlr.fit(X_train, T_train, E_train, lr=1e-3, num_epochs = 500,\n",
        "           init_method='orthogonal', optimizer = 'rprop')\n",
        "\n",
        "\n",
        "#### 5 - Cross Validation / Model Performances\n",
        "c_index = concordance_index(n_mtlr, X_test, T_test, E_test) #0.51\n",
        "print('C-index: {:.2f}'.format(c_index))\n",
        "\n",
        "ibs = integrated_brier_score(n_mtlr, X_test, T_test, E_test, t_max=30,\n",
        "            figure_size=(20, 6.5) )\n",
        "print('IBS: {:.2f}'.format(ibs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ0-DmcIIm5f"
      },
      "source": [
        "**Non-Parametric**\n",
        "*Kaplan Meier model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBWmiCiE2tIY"
      },
      "source": [
        "from pysurvival.models.non_parametric import KaplanMeierModel\n",
        "from pysurvival.utils.display import display_non_parametric"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Q-xjb_2-ux"
      },
      "source": [
        "T = df11.iloc[:,1]\n",
        "E = df11.iloc[:,0]\n",
        "\n",
        "# Initializing the KaplanMeierModel\n",
        "km_model = KaplanMeierModel()\n",
        "\n",
        "# Fitting the model \n",
        "km_model.fit(T, E, alpha=0.95)\n",
        "\n",
        "# Displaying the survival function and confidence intervals\n",
        "display_non_parametric(km_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4jwMhz8Iw8q"
      },
      "source": [
        "**Non-Parametric**\n",
        "*Smooth Kaplan Meier model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2x9FNRW3ipg"
      },
      "source": [
        "from pysurvival.models.non_parametric import SmoothKaplanMeierModel"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO745y4k3tT6"
      },
      "source": [
        "# Initializing the SmoothKaplanMeierModel\n",
        "skm_model = SmoothKaplanMeierModel(bandwidth=1., kernel='Cosine')\n",
        "\n",
        "# Fitting the model and display the survival function and confidence intervals\n",
        "skm_model.fit(T, E, alpha=0.95)\n",
        "\n",
        "# Displaying the survival function and confidence intervals\n",
        "display_non_parametric(skm_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvCLdtbtJFb2"
      },
      "source": [
        "**Parametric models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBNXM14H3ylB"
      },
      "source": [
        "from pysurvival.models.parametric import GompertzModel\n",
        "from pysurvival.models.parametric import ExponentialModel\n",
        "from pysurvival.models.parametric import WeibullModel\n",
        "from pysurvival.models.parametric import LogLogisticModel\n",
        "from pysurvival.models.parametric import LogNormalModel"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k98Y9FwPJQgl"
      },
      "source": [
        "*Gompertz*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAzNGqYw4pv1"
      },
      "source": [
        "#### 4 - Creating an instance of the Gompertz model and fitting the data.\n",
        "# Building the model\n",
        "gomp_model = GompertzModel()\n",
        "gomp_model.fit(X_train, T_train, E_train, lr=1e-2, init_method='zeros',\n",
        "    optimizer ='adam', l2_reg = 1e-3, num_epochs=2000)\n",
        "\n",
        "\n",
        "#### 5 - Cross Validation / Model Performances\n",
        "c_index = concordance_index(gomp_model, X_test, T_test, E_test) #0.55\n",
        "print('C-index: {:.2f}'.format(c_index))\n",
        "\n",
        "ibs = integrated_brier_score(gomp_model, X_test, T_test, E_test, t_max=30,\n",
        "            figure_size=(20, 6.5) )\n",
        "print('IBS: {:.2f}'.format(ibs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqs4tx_rJaIa"
      },
      "source": [
        "*Exponential*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7E5IplW4z-R"
      },
      "source": [
        "#### 4 - Creating an instance of the Gompertz model and fitting the data.\n",
        "# Building the model\n",
        "exp_model = ExponentialModel()\n",
        "exp_model.fit(X_train, T_train, E_train, lr=1e-2, init_method='zeros',\n",
        "    optimizer ='adam', l2_reg = 1e-3, num_epochs=2000)\n",
        "\n",
        "\n",
        "#### 5 - Cross Validation / Model Performances\n",
        "c_index = concordance_index(exp_model, X_test, T_test, E_test) #0.56\n",
        "print('C-index: {:.2f}'.format(c_index))\n",
        "\n",
        "ibs = integrated_brier_score(exp_model, X_test, T_test, E_test, t_max=30,\n",
        "            figure_size=(20, 6.5) )\n",
        "print('IBS: {:.2f}'.format(ibs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CHY2Hn4JfXe"
      },
      "source": [
        "*Log-Logistic*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhA6jW4Z5ETp"
      },
      "source": [
        "#### 4 - Creating an instance of the Gompertz model and fitting the data.\n",
        "# Building the model\n",
        "loglog_model = LogLogisticModel()\n",
        "loglog_model.fit(X_train, T_train, E_train, lr=1e-2, init_method='zeros',\n",
        "    optimizer ='adam', l2_reg = 1e-3, num_epochs=2000)\n",
        "\n",
        "\n",
        "#### 5 - Cross Validation / Model Performances\n",
        "c_index = concordance_index(loglog_model, X_test, T_test, E_test) #0.56\n",
        "print('C-index: {:.2f}'.format(c_index))\n",
        "\n",
        "ibs = integrated_brier_score(loglog_model, X_test, T_test, E_test, t_max=30,\n",
        "            figure_size=(20, 6.5) )\n",
        "print('IBS: {:.2f}'.format(ibs))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}